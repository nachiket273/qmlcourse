(qmlkinds)=

# О квантовом машинном обучении

Автор(ы):

- [Синченко Семен](https://github.com/SemyonSinchenko)


Квантовое машинное обучение -- это на самом деле огромная область, и наш курс охватывает лишь небольшую ее часть. В этой обзорной лекции мы попробуем взглянуть на картину в целом и посмотреть, какие есть направления в этой интересной и динамично развивающейся области.

```{note}
Эта статья является исключительно обзорной -- в ней будет много красивых картинок, но мы не будем вдаваться в формулы, которые могут эти картинки объяснить. Цель лекции -- познакомить читателя с тем, как машинное обучение может быть применено в разных задачах, связанных с квантовыми вычислениями и квантовой физикой.
```

## Виды квантового машинного обучения

Как мы помним из [лекции по машинному обучению](../../ml/ru/ml_l1.md), в таких задачах у нас есть две важных составляющих -- данные и алгоритм. В случае квантового машинного обучения у нас появляется некоторая "вариативность":

- квантовые данные
- квантовый алгоритм
- классические данные
- классический алгоритм

На базе этого можно построить классификацию машинного обучения.

```{figure} /_static/qmlkinds/ru/qmlkinds/Qml_approaches.png
:width: 300px

Виды машинного обучения в зависимости от типа данных и алгоритма.
```

Когда мы имеем классические данные и классический алгоритм, то это как раз обычное машинное обучение, рассмотренное во вводной лекции курса. А вот остальные виды мы рассмотрим далее.

## Квантовые данные и классический алгоритм

Классическое машинное обучение применительно к квантовым данным -- это очень активно развивающаяся область квантовой физики и квантовой химии. Главный вопрос в данном случае -- что именно мы пониманием под "квантовыми данными". Но мы будем придерживаться максимально широкой трактовки этого понятия. Далее рассмотрим примеры возможного применения ML в задачах квантовой физики и химии.

(NQS)=
### NQS

**N**eural **Q**uantum **S**tates это очень перспективное улучшение квантового Монте-Карло -- популярного метода приближенного решения задач квантовой физики. Мы будем подробно рассматривать проблему нахождения энергетических спектров квантомеханических систем, а также моделирования квантовой динамики в блоке о проблемах квантового машинного обучения. Пока нам достаточно знания того, что эти задачи являются вычислительно трудными и их прямое численное решение очень быстро становится невозможным по мере увеличения размера системы и числа взаимодействующих частиц. В подходе **NQS**, впервые опубликованном в журнале _Science_ {cite}`carleo2017nqs`, предложено моделировать волновую функцию $\ket{\Psi}$ физической системы при помощи глубокой нейронной сети. Это дает ряд преимуществ над обычным квантовым Монте-Карло в плане точности моделирования, а также позволяет явно симулировать _time-dependent_ уравнение Шредингера. Относительно другого популярного метода, который называется _Matrix Product State_ **NQS** дает лучшую масштабируемость и меньшую аппроксимацию сложность, которая оказывается линейной по числу частиц в физической системе.

```{figure} /_static/qmlkinds/ru/qmlkinds/NQS.png
:width: 600px

Сходимость **NQS** по энергии в зависимости от числа эпох обучения. По вертикали значение энергии на один спин, по горизонтали эпохи обучения. Пунктиром отмечено точное значение, полученное прямой диагонализацией гамильтониана. Слева общий вид, справа -- _сверхтонкая_ сходимость вблизи энергии основного состояния. Источник {cite}`carleo2017nqs`.
```

### CNN над потенциалами

Другим интересным подходом является применение _Convolutional Neural Networks_ (_CNN_) -- специального класса глубоких нейронных сетей, разработанных для обработки изображений, к физическим потенциалам. Дело в том, что трехмерный энергетический потенциал можно представить как 2D изображение. Например, можно взять периодическую потенциальную энергию, создаваемую атомами в кристаллической решетке и рассмотреть, как будет вести себя электрон в таком потенциале.

```{figure} /_static/qmlkinds/ru/qmlkinds/CNN_over_psi.png
:width: 650px

Иллюстрация применения _CNN_ на энергетических потенциалах. Источник {cite}`mills2017deep`.
```

Существует ограниченный набор частных случаев, когда эта задача может быть решена аналитически. Используя такие точные решения, мы составляем обучающую выборку, тренируем _CNN_, а потом можем применять ее к другим, более сложным потенциалам.

### Решение уравнения Шредингера

Другим примером решения задачи об энергетических уровнях является применение глубокой нейронной сети, которая на вход принимает _Slater determinants_, _Jastrow factor_ и другие известные способы приближенного описания квантомеханических систем. А на выходе из такой глубокой нейронной сети получаем волновую функцию системы. Таким образом, получается объединить все преимущества хорошо изученных физических представлений с высокой экспрессивностью глубоких нейронных сетей {cite}`hermann2020deep`.

```{figure} /_static/qmlkinds/ru/qmlkinds/PauliNet.png
:width: 350px

Архитектура подхода _PauliNet_. Источник {cite}`hermann2020deep`.
```

Такой подход дает фантастическую точность по сравнению с другими подходами и выглядит очень перспективно, так как дополнительно позволяет получить очень хорошую масштабируемость из-за возможности снизить число _slater determinants_.

### RNN для моделирования волновых функций

Другой похожий на {ref}`NQS` подход -- это использовать для аппроксимации волновой функции рекуррентные нейронные сети вместо машин Больцмана.

```{figure} /_static/qmlkinds/ru/qmlkinds/RNN.png
:width: 300px

Результаты _RNN_-модели для аппроксимации волновых функций. Можно получать не только значение энергии, но и ожидаемые значения других операторов, например, операторов спина или операторов спиновых корреляций. Источник {cite}`hibat2020recurrent`. На графике (a) приведена зависимость энергии от эпохи обучения. На графике (b) приведены зависимости собственного значения операторов спиновых корреляций 40-го (центрального) спина с _n_-ым от номера _n_. На графике (c) приведено распределение значений оператора спина по длине цепочки спинов.
```

В данном подходе мы строим "последовательную" волновую функцию многочастичной квантовой системы, "подавая" туда по одной каждую частицу. А так как нейронная сеть -- рекуррентная, мы по сути последовательно строим волновую функцию многочастичной системы.

### Квантовая томография

Мы немного рассказывали о задаче квантовой томографии в [лекции про смешанные состояния](../../qc/ru/mixedstates.md). Правда, там привели пример использования метода максимизации правдоподобия для решения задачи восстановления состояния по измерениям. Оказывается, что для этих целей можно использовать глубокие нейронные сети. Один из таких подходов описан в {cite}`ahmed2021quantum`. Суть подхода в том, что используются генеративные сети с условием -- _Conditional GAN_ (C-GAN) для восстановления состояния. Для создания матрицы плотности используется генератор, а для вычисления ошибки относительно реальных результатов измерений -- дискриминатор.

```{figure} /_static/qmlkinds/ru/qmlkinds/C-GAN.png
:width: 550px

Иллюстрация подхода _C-GAN_.
```

### Заключение к подразделу

В целом, применение классических алгоритмов машинного обучения к задачам квантовой физики и квантовой химии -- очень перспективная область. Мы еще немного коснемся этой темы, когда будем рассматривать решение задачи о собственных значениях гамильтонианов. Однако, эта тема выходит за рамки нашего курса.

## Классические данные и квантовый алгоритм

Теперь перейдем к ситуации, когда мы рассматриваем классические данные (задачи классификации и регрессии) и применяем к ним машинное обучение, реализуемое на квантовом компьютере как набор операций над кубитами.

### HHL

Один из самых известных алгоритмов квантового машинного обучения -- это алгоритм **HHL** {cite}`Harrow_2009`, которому в нашем курсе [посвящена отдельная продвинутая лекция](./hhl_algorithm.md). Это алгоритм решения системы линейных уравнений за $O(N \log N)$ операций. Так как к решению системы уравнений можно свести огромное число задач реального мира, этот алгоритм обладает огромным потенциалом. К сожалению, сегодня его практическое применение сильно ограничено несколькими вещами:

- необходимость эффективной генерации начального состояния -- без этого достижения превосходства **HHL** невозможно;
- высокие требования к точности операций, а также необходимость в большом числе кубитов.

Этот алгоритм является примером чисто квантового алгоритма, где абсолютно все операции выполняются на квантовом компьютере.

### Quantum k-NN

Другой пример полностью квантового алгоритма -- это модификация классического алгоритма ближайшего соседа, с той лишь разницей, что для вычисления расстояний между точками в $N$-мерном пространстве мы используем квантовый компьютер. Этот алгоритм называется _Quantum k-NN_ (_Quantum k Nearest Neighbours_). Сегодня существует довольно много потенциально эффективных реализаций этого алгоритма, которые отличаются в основном тем, какая используется метрика расстояния в гильбертовом пространстве. Одна из реализаций [рассмотрена в продвинутой лекции нашего курса](./qknn.md). К сожалению, практическое использование таких алгоритмов сегодня ограничено тем, что для них требуется эффективная квантовая память -- _quantum Random Access Memory_.

### Заключение к подразделу

Сегодня мы живем в так называемой _NISQ_ (_Noisy Intermediate-Scale Quantum_) эпохе, то есть когда у нас есть квантовые компьютеры лишь ограниченного размера и с относительно большим уровнем шумов. А чисто квантовые алгоритмы квантового машинного обучения очень требовательны именно к точности вычислений. Также в таких алгоритмах большой проблемой является постоянная необходимость сложной операции перевода классических данных в квантовые. В теории, эта проблема исчезнет с появлением _qRAM_, однако сегодня такая "квантовая память" еще не существует и даже пока нет однозначного понимания того, как именно ее делать. Все это сильно ограничивает потенциал полностью квантовых подходов. Далее мы рассмотрим более перспективный в _NISQ_-эпоху подход -- гибридное квантово-классическое машинное обучение.

## Гибридное обучение

Большая часть из оставшихся лекций нашего курса будет посвящена как раз гибридным методам квантового машинного обучения. В этих методах часть алгоритма реализуется в виде квантовых вентилей, а часть выполняется на классическом компьютере.

### VQC

**V**ariational **Q**uantum **C**ircuits, или просто вариационные схемы, -- это одно из центральных понятий в гибридном квантово-классическом обучении. Основная идея заключается в том, что мы используем квантовую операцию, которая задается каким-то классическим параметром. Обычно это одна или несколько операций "вращений" на сфере Блоха, про которые [мы говорили в лекции про квантовые гейты](../../qc/ru/gates.html#id5). При этом вариация классического параметра осуществляется на классическом компьютере, например, при помощи градиентного спуска.

```{figure} /_static/vqc/ru/diagram.png
:width: 200px

Схема работы вариционной квантовой схемы.
```

В нашем курсе теме вариационных схем будет посвящено несколько лекций:

- [вариационные квантовые схемы](../../vqc/ru/vqc.md)
- [градиенты **VQC**](../../grads/ru/gradients.md)
- [продвинутая лекция по градиентам **VQC**](../../grads/ru/hogradients.md)

Также мы часто будем возвращаться понятию VQC в теме квантовых нейросетей, а также в блоке про решение задачи собственных значений при помощи алгоритма _Variational Quantum Eigensolver_.

### Квантовые нейросети

Квантовые "нейронные сети" -- это как раз пример, когда мы комбинируем вариационные слои вместе с обычными слоями нейронных сетей.

```{figure} /_static/qnn/ru/qnntfq.png
:width: 550px

Пример гибридной квантовой нейросети. Источник {cite}`broughton2021tensorflow`.
```

На картинке выше приведен пример комбинации вариационных квантовых схем и классических слоев обычных глубоких нейронных сетей. При этом оптимизация параметров выполняется при помощи единого процесса _backpropagation_, с той лишь разницей, что для классических и квантовых слоев немного по-разному вычисляется градиент для параметров конкретного слоя. Теме квантовых нейронных сетей в нашем курсе будет посвящен целый блок, где будет, в том числе, рассказано еще и об аналоге сверточного слоя с использованием **VQC**.

### Квантовые ядра

Квантовые ядра и квантовый алгоритм _Support Vector Machine_ (_SVM_) -- это другой пример, как можно объединить квантовые гейты с классическими алгоритмами. Математике "под капотом" классического _SVM_ у нас будет посвящена отдельная лекция, но если кратко, то суть там в том, что решение задачи об оптимальной разделяющей гиперплоскости (другими словами, об оптимальной классификации) можно выразить через скалярные произведения точек обучающей выборки. Причем не обязательно в исходном пространстве, а в любом гильбертовом пространстве. А как мы помним, квантовые гейты как раз представляют собой операции в гильбертовом пространстве, причем экспоненциально большого размера. Так и появляется идея гибридного _SVM_ -- мы переписываем скалярные произведения точек как результат измерения параметризованных квантовых схем, где параметры это и есть компоненты каждой из точек. А дальше уже применяем классические методы решения оптимизационной задачи. Этой теме у нас будет посвящена отдельная лекция.

### Оптимизация энергии

Еще один интересный и перспективный класс задач, которые можно решать гибридными методами -- это оптимизация энергии гамильтониана. Может показаться, что это еще что-то из области квантовой физики, но на самом деле в блоке о проблемах квантового машинного обучения мы покажем, как к задаче поиска основного состояния системы, описанной квантовым оператором -- гамильтонианом, можно свести огромное число задач реального мира. Например, это задача Коммивояжера, очень важная в области логистики, или задача о нахождении энергий электронов, которая играет важную роль в разработке лекарств или создании новых материалов.

## Заключение

В этой лекции мы познакомились с тем, каким может быть квантовое машинное обучение. Мы узнали, что бывают:

- классические алгоритмы над квантовыми данными;
- квантовые алгоритмы над классическими данными;
- гибридные алгоритмы.

Именно гибридные алгоритмы наиболее перспективны в _NISQ_-эпоху, и именно им будет посвящена большая часть оставшихся лекций курса.
